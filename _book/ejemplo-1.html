<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Ejemplo | Regresión Lineal múltiple</title>
  <meta name="description" content="Este libro es una introducción al analisis de regresion por medio del modelo lineal multiple utilizando el lenguaje de programacion R con el paquete bookdown para la escritura de libros." />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Ejemplo | Regresión Lineal múltiple" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Este libro es una introducción al analisis de regresion por medio del modelo lineal multiple utilizando el lenguaje de programacion R con el paquete bookdown para la escritura de libros." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Ejemplo | Regresión Lineal múltiple" />
  
  <meta name="twitter:description" content="Este libro es una introducción al analisis de regresion por medio del modelo lineal multiple utilizando el lenguaje de programacion R con el paquete bookdown para la escritura de libros." />
  

<meta name="author" content="Sebastian Zabala" />


<meta name="date" content="2024-02-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modelos-de-regresión-lineal-múltiple.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Regresión Lineal múltiple</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prólogo</a></li>
<li class="chapter" data-level="1" data-path="modelos-de-regresión-lineal-múltiple.html"><a href="modelos-de-regresión-lineal-múltiple.html"><i class="fa fa-check"></i><b>1</b> Modelos de regresión lineal múltiple</a>
<ul>
<li class="chapter" data-level="1.1" data-path="modelos-de-regresión-lineal-múltiple.html"><a href="modelos-de-regresión-lineal-múltiple.html#intro"><i class="fa fa-check"></i><b>1.1</b> Introducción</a></li>
<li class="chapter" data-level="1.2" data-path="modelos-de-regresión-lineal-múltiple.html"><a href="modelos-de-regresión-lineal-múltiple.html#Estimacion-M.C.O."><i class="fa fa-check"></i><b>1.2</b> Estimación de los parámetros de la ecuación de regresión por el método de mínimo cuadrado ordinario (M.C.O.)</a></li>
<li class="chapter" data-level="" data-path="modelos-de-regresión-lineal-múltiple.html"><a href="modelos-de-regresión-lineal-múltiple.html#ejemplo"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="1.3" data-path="modelos-de-regresión-lineal-múltiple.html"><a href="modelos-de-regresión-lineal-múltiple.html#Enfoque-matricial"><i class="fa fa-check"></i><b>1.3</b> Enfoque matricial para un modelo de regresión lineal múltiple</a></li>
<li class="chapter" data-level="1.4" data-path="modelos-de-regresión-lineal-múltiple.html"><a href="modelos-de-regresión-lineal-múltiple.html#supuestos-básicos-del-modelo-de-regresión-utilizando-notación-matricial"><i class="fa fa-check"></i><b>1.4</b> Supuestos básicos del modelo de regresión utilizando notación matricial</a></li>
<li class="chapter" data-level="1.5" data-path="modelos-de-regresión-lineal-múltiple.html"><a href="modelos-de-regresión-lineal-múltiple.html#estimación-de-los-parámetros-del-modelo-por-el-método-m.c.o.-utilizando-la-notación-matricial."><i class="fa fa-check"></i><b>1.5</b> Estimación de los parámetros del modelo por el método M.C.O., utilizando la notación matricial.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ejemplo-1.html"><a href="ejemplo-1.html"><i class="fa fa-check"></i>Ejemplo</a>
<ul>
<li class="chapter" data-level="1.6" data-path="ejemplo-1.html"><a href="ejemplo-1.html#propiedades-de-los-estimadores-mínimos-cuadrados"><i class="fa fa-check"></i><b>1.6</b> Propiedades de los estimadores mínimos cuadrados</a></li>
<li class="chapter" data-level="1.7" data-path="ejemplo-1.html"><a href="ejemplo-1.html#estimación-de-sigma2"><i class="fa fa-check"></i><b>1.7</b> Estimación de <span class="math inline">\(\sigma^{2}\)</span></a></li>
<li class="chapter" data-level="1.8" data-path="ejemplo-1.html"><a href="ejemplo-1.html#prueba-de-hipótesis-en-la-regresión-múltiple"><i class="fa fa-check"></i><b>1.8</b> Prueba de hipótesis en la regresión múltiple</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="ejemplo-1.html"><a href="ejemplo-1.html#prueba-para-la-significancia-de-la-regresión."><i class="fa fa-check"></i><b>1.8.1</b> Prueba para la significancia de la regresión.</a></li>
<li class="chapter" data-level="1.8.2" data-path="ejemplo-1.html"><a href="ejemplo-1.html#prueba-para-los-coeficientes-de-regresión."><i class="fa fa-check"></i><b>1.8.2</b> Prueba para los coeficientes de regresión.</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="ejemplo-1.html"><a href="ejemplo-1.html#estimación-de-los-intervalos-de-confianza-en-la-regresión-lineal-múltiple"><i class="fa fa-check"></i><b>1.9</b> Estimación de los intervalos de confianza en la regresión lineal múltiple</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="ejemplo-1.html"><a href="ejemplo-1.html#intervalos-de-confianza-para-los-parámetros."><i class="fa fa-check"></i><b>1.9.1</b> Intervalos de confianza para los parámetros.</a></li>
<li class="chapter" data-level="1.9.2" data-path="ejemplo-1.html"><a href="ejemplo-1.html#intervalo-de-confianza-para-la-respuesta-media-eyx0."><i class="fa fa-check"></i><b>1.9.2</b> Intervalo de confianza para la respuesta media e(y/x0).</a></li>
<li class="chapter" data-level="1.9.3" data-path="ejemplo-1.html"><a href="ejemplo-1.html#intervalo-de-confianza-para-haty_0-observación-futura."><i class="fa fa-check"></i><b>1.9.3</b> Intervalo de confianza para <span class="math inline">\(\hat{y}_{0}\)</span> (observación futura).</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Regresión Lineal múltiple</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ejemplo-1" class="section level1 unnumbered hasAnchor">
<h1>Ejemplo<a href="ejemplo-1.html#ejemplo-1" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>En el ejemplo anterior se ilustro el ajuste del modelo de regresión múltiple.
<span class="math display">\[
\begin{equation}
y=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+\varepsilon
\end{equation}
\]</span>
Donde <span class="math inline">\(y\)</span> es el numero de pasajeros observado que escogen viajar por Hop Scotch, <span class="math inline">\(x_{1}\)</span> es el gasto en publicidad y <span class="math inline">\(x_{2}\)</span> es el ingreso nacional. Ahora se utilizara el enfoque matricial para ajustar el modelo de regresión anterior a este conjunto de datos. La matriz <span class="math inline">\(\boldsymbol{X}\)</span> y el vector <span class="math inline">\(\boldsymbol{Y}\)</span> para este modelo son:</p>
<p><span class="math display">\[
\begin{equation}
\boldsymbol{X} = \begin{bmatrix}
1&amp;  10&amp; 2.40\\
1&amp;  12&amp; 2.72\\
1&amp;  8&amp; 2.08\\
\vdots &amp;  \vdots&amp; \vdots\\
1&amp;  12&amp; 2.17
\end{bmatrix}_{15x3}
\boldsymbol{Y} = \begin{bmatrix}
15\\
17\\
13\\
\vdots \\
16
\end{bmatrix}_{15x1}
(\#matrices-regresion-multiple)
\end{equation}
\]</span>
La matriz <span class="math inline">\(\boldsymbol{X&#39;X}\)</span> es</p>
<p><span class="math display">\[
\begin{equation}
\boldsymbol{X&#39;X}=\begin{bmatrix}
1&amp;  1&amp;  \cdots&amp; 1\\
10&amp;  12&amp;  \cdots&amp; 12\\
2.40&amp;  2.72&amp;  \cdots&amp;  2.17
\end{bmatrix}_{3x15}
\begin{bmatrix}
1&amp;  10&amp; 2.40\\
1&amp;  12&amp; 2.72\\
\vdots &amp;  \vdots&amp; \vdots\\
1&amp;  12&amp; 2.17
\end{bmatrix}_{15x3} \\
= \begin{bmatrix}
15&amp;   187 &amp; 40.29\\
187&amp;   2469&amp; 525.38\\
40.29  &amp;  525.38 &amp; 113.3387
\end{bmatrix}
\end{equation}
\]</span>
y el vector <span class="math inline">\(\boldsymbol{X&#39;Y}\)</span> es:</p>
<p>$$
<span class="math display">\[\begin{equation}
\boldsymbol{X&#39;Y}=\begin{bmatrix}
1&amp;  1&amp;  \cdots&amp; 1\\
10&amp;  12&amp;  \cdots&amp; 12\\
2.40&amp;  2.72&amp;  \cdots&amp;  2.17
\end{bmatrix}_{3x15}

\end{equation}\]</span>
$$</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="ejemplo-1.html#cb28-1" tabindex="-1"></a>identidad <span class="ot">&lt;-</span>  <span class="fu">rep</span>(<span class="dv">1</span>,<span class="dv">15</span>)</span>
<span id="cb28-2"><a href="ejemplo-1.html#cb28-2" tabindex="-1"></a>publicidad <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>,<span class="dv">12</span>,<span class="dv">8</span>,<span class="dv">17</span>,<span class="dv">10</span>,<span class="dv">15</span>,<span class="dv">10</span>,<span class="dv">14</span>,<span class="dv">19</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">13</span>,<span class="dv">16</span>,<span class="dv">10</span>,<span class="dv">12</span>)</span>
<span id="cb28-3"><a href="ejemplo-1.html#cb28-3" tabindex="-1"></a>ingreso_nacional <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">2.4</span>,<span class="fl">2.72</span>,<span class="fl">2.08</span>,<span class="fl">3.68</span>,<span class="fl">2.56</span>,<span class="fl">3.36</span>,<span class="fl">2.24</span>,<span class="fl">3.2</span>,<span class="fl">3.84</span>,<span class="fl">2.72</span>,<span class="fl">2.07</span>,<span class="fl">2.33</span>,<span class="fl">2.98</span>,<span class="fl">1.94</span>,<span class="fl">2.17</span>)</span>
<span id="cb28-4"><a href="ejemplo-1.html#cb28-4" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">cbind</span>(identidad,publicidad, ingreso_nacional)</span>
<span id="cb28-5"><a href="ejemplo-1.html#cb28-5" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>##       identidad publicidad ingreso_nacional
##  [1,]         1         10             2.40
##  [2,]         1         12             2.72
##  [3,]         1          8             2.08
##  [4,]         1         17             3.68
##  [5,]         1         10             2.56
##  [6,]         1         15             3.36
##  [7,]         1         10             2.24
##  [8,]         1         14             3.20
##  [9,]         1         19             3.84
## [10,]         1         10             2.72
## [11,]         1         11             2.07
## [12,]         1         13             2.33
## [13,]         1         16             2.98
## [14,]         1         10             1.94
## [15,]         1         12             2.17</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="ejemplo-1.html#cb30-1" tabindex="-1"></a>matriz_productos_cruzados <span class="ot">&lt;-</span> <span class="fu">t</span>(x) <span class="sc">%*%</span> x</span>
<span id="cb30-2"><a href="ejemplo-1.html#cb30-2" tabindex="-1"></a>matriz_productos_cruzados</span></code></pre></div>
<pre><code>##                  identidad publicidad ingreso_nacional
## identidad            15.00     187.00          40.2900
## publicidad          187.00    2469.00         525.3800
## ingreso_nacional     40.29     525.38         113.3387</code></pre>
<div id="propiedades-de-los-estimadores-mínimos-cuadrados" class="section level2 hasAnchor" number="1.6">
<h2><span class="header-section-number">1.6</span> Propiedades de los estimadores mínimos cuadrados<a href="ejemplo-1.html#propiedades-de-los-estimadores-mínimos-cuadrados" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Las propiedades estadísticas de los estimadores mínimos cuadrados <span class="math inline">\(\hat{\beta_{o}},\hat{\beta_{1}},...,\hat{\beta_{k}}\)</span> pueden determinarse con facilidad, bajo ciertas condiciones sobre los términos del error <span class="math inline">\(\varepsilon_{1},\varepsilon_{2},...,\varepsilon_{n}\)</span> del modelo de regresión. Paralelamente con las suposiciones hechas en el modelo de regresión lineal simple, aquí se supondrá que los errores <span class="math inline">\(\varepsilon_{i}\)</span> son estadisticamente independientes con media cero y varianza <span class="math inline">\(\sigma_{2}\)</span>. Bajo estas suposiciones, los estimadores mínimos cuadrados ordinarios <span class="math inline">\(\hat{\beta_{o}},\hat{\beta_{1}},...,\hat{\beta_{k}}\)</span> son estimadores insesgados de los coeficientes de regresión <span class="math inline">\(\beta_{o},\beta_{1},...,\beta_{k}\)</span>. Esta propiedad puede demostrarse de la siguiente manera:</p>
<p><span class="math display">\[
\begin{equation}
E(\boldsymbol{\hat{\beta}}) = E\boldsymbol{[(X&#39;X)^{-1}X&#39;Y]} \\
= E\boldsymbol{[(X&#39;X)^{-1}X&#39;(X\beta + \varepsilon)]} \\
= E\boldsymbol{[(X&#39;X)^{-1}X&#39;X\beta + (X&#39;X)^{-1}X&#39; + \varepsilon)]} \\
= E\boldsymbol{[I\beta + (X&#39;X)^{-1}X&#39;\varepsilon)]} \\
= E\boldsymbol{[I\beta] + E[(X&#39;X)^{-1}X&#39;\varepsilon)]} \\
= E\boldsymbol{[\beta] + (X&#39;X)^{-1}X&#39;E[\varepsilon]} \\
E(\boldsymbol{\hat{\beta}})= \boldsymbol{\beta}
\end{equation}
\]</span></p>
<p>Puesto que <span class="math inline">\(E[\boldsymbol{\varepsilon]}=0\)</span>. Por lo tanto <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> se expresan en términos de los elementos de la inversa de la matriz X’X. La inversa de X´X multiplicada por la constante <span class="math inline">\(\sigma^{2}\)</span> representa la matriz de varianza-covarianza de los coeficientes de regresión <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span>. Los elementos de la diagonal principal de <span class="math inline">\(\sigma^{2}(X&#39;X)^{-1}\)</span> son las varianzas de <span class="math inline">\(\hat{\beta_{o}},\hat{\beta_{1}},...,\hat{\beta_{k}}\)</span> mientras que los elementos que están fuera de la diagonal principal son las covarianzas.</p>
<p>Entonces <span class="math inline">\(\sum=Var(\boldsymbol{\hat{\beta}})=\sigma^{2}(X&#39;X)^{-1}\)</span> si llamamos <span class="math inline">\(C=(X&#39;X)^{-1}\)</span>, entonces la varianza de <span class="math inline">\(\hat{\beta_{j}}\)</span> es <span class="math inline">\(\sigma^{2}C_{jj}\)</span> y la covarianza entre <span class="math inline">\(\hat{\beta_{i}}\)</span> y <span class="math inline">\(\hat{\beta_{j}}\)</span> es <span class="math inline">\(\sigma^{2}C_{jj}\)</span>.</p>
<p>La matriz C es una matriz simétrica que tiene la siguiente estructura:</p>
<p><span class="math display">\[
\begin{equation}
C=\begin{bmatrix}
C_{00}&amp;  C_{01}&amp;  \cdots&amp; C_{0K}\\
C_{10}&amp;  C_{11}^2&amp;  \cdots&amp; C_{1K}\\
\vdots &amp;  \vdots &amp;  \ddots &amp; \vdots\\
C_{K0}&amp;  C_{1k}&amp;  \cdots&amp; C_{kk}
\end{bmatrix}_{pxp}
j = 0,1,2,...,k
p=k+1
\end{equation}
\]</span></p>
<p>En general: <span class="math display">\[Var(\hat{\beta})= \sigma^{2}C_{jj}\]</span> para j = 0, 1, 2, …, k <span class="math display">\[Cov(\hat{\beta_{j}},\hat{\beta_{j}})=\sigma^{2}C_{jj}\]</span> para i≠j.</p>
<p>La matriz de varianza-covarianza de <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span>, viene dada por:</p>
<p><span class="math display">\[
\begin{equation}
\sum = Var(\boldsymbol{\hat{\beta}})=E[(\boldsymbol{\hat{\beta}}-E(\boldsymbol{\hat{\beta}})(\boldsymbol{\hat{\beta}}-E(\boldsymbol{\hat{\beta}}))&#39;]
\end{equation}
\]</span></p>
<p><span class="math display">\[
=E[(\boldsymbol{\hat{\beta}}-\boldsymbol{\beta})(\boldsymbol{\hat{\beta}}-\boldsymbol{\beta})&#39;]
\]</span>
donde:
<span class="math display">\[
\boldsymbol{\hat{\beta}-\beta=(X&#39;X)^{-1}X&#39;Y-\beta}
\]</span>
<span class="math display">\[\boldsymbol{=(X&#39;X)^{-1}X&#39;(X\beta+\varepsilon)-\beta}\]</span>
<span class="math display">\[\boldsymbol{=(X&#39;X)^{-1}X&#39;X\beta + (X&#39;X)^{-1}X&#39;                   \varepsilon-\beta}\]</span> <span class="math display">\[\boldsymbol{=I\beta+(X&#39;X)^{-1}X&#39;\varepsilon-\beta}\]</span> <span class="math display">\[=\boldsymbol{(X&#39;X)^{-1}X&#39;\varepsilon}\]</span> Por lo tanto:</p>
<p><span class="math display">\[\sum=Var(\boldsymbol{\hat{\beta}})= E[[\boldsymbol{(X&#39;X)^{-1}X&#39;\varepsilon}][\boldsymbol{(X&#39;X)^{-1}X&#39;\varepsilon}]&#39;]\]</span> <span class="math display">\[\boldsymbol{(X&#39;X)^{-1}X&#39;E[\varepsilon\varepsilon&#39;]X(X&#39;X)^{-1}}\]</span> <span class="math display">\[=\boldsymbol{(X&#39;X)^{-1}X&#39;\sigma^{2}IX(X&#39;X)^{-1}}\]</span> <span class="math display">\[\sigma^{2}\boldsymbol{(X&#39;X)^{-1}X&#39;X(X&#39;X)^{-1}}\]</span> <span class="math display">\[=\sigma^{2}\boldsymbol{(X&#39;X)^{-1}}\]</span></p>
</div>
<div id="estimación-de-sigma2" class="section level2 hasAnchor" number="1.7">
<h2><span class="header-section-number">1.7</span> Estimación de <span class="math inline">\(\sigma^{2}\)</span><a href="ejemplo-1.html#estimación-de-sigma2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Al igual que en el caso de la regresión lineal simple, la estimación de <span class="math inline">\(\sigma^2\)</span> está definida en términos de la suma de cuadrados de los residuos.</p>
<p><span class="math display" id="eq:suma-error-cuadratico-regresion-lineal">\[
\begin{equation}
SCE = \sum_{i=1}^{n}(y_{i}-\hat{y_{i}})^{2} = \sum_{i=1}^{n}e_{i}^{2} = \boldsymbol{\varepsilon&#39;\varepsilon}
\tag{1.11}
\end{equation}
\]</span> Sustituyendo <span class="math inline">\(\boldsymbol{\varepsilon=Y-X\hat{\beta}}\)</span>, se tiene: <span class="math display">\[
\begin{equation}
SCE = \boldsymbol{(Y-X\hat{\beta})&#39;(Y-X\hat{\beta})}
\end{equation}
\]</span> <span class="math display">\[
\begin{equation}
=\boldsymbol{Y&#39;Y - \hat{\beta}X&#39;Y-Y&#39;X\hat{\beta}+\hat{\beta} &#39;X\hat{\beta}}
\end{equation}
\]</span></p>
<p><span class="math display">\[
= \boldsymbol{Y&#39;Y-2\hat{\beta}&#39;X&#39;Y+\beta&#39;X&#39;X\hat{\beta}}
\]</span> Puesto que: $ $</p>
<p>La suma de cuadrados de residuales tiene n - p grados de libertad. Entonces:</p>
<p><span class="math display" id="eq:error-cuadratico-medio-regresion-lineal">\[
\begin{equation}
CME= \frac{SCE}{n-p}
\tag{1.12}
\end{equation}
\]</span> Pero el valor esperado de CME es <span class="math inline">\(\sigma^{2}\)</span> y un estimador insesgado de <span class="math inline">\(\sigma^{2}\)</span> es:</p>
<p><span class="math display" id="eq:estimacion-error-cuadratico-medio-regresion-lineal">\[
\begin{equation}
\hat{\sigma}^{2}=CME=\frac{SCE}{n-p}=\frac{\boldsymbol{Y&#39;Y-\hat{\beta}&#39;X&#39;Y}}{n-p}
\tag{1.13}
\end{equation}
\]</span></p>
<p>Las varianzas y covarianzas de los estimadores vienen dadas por:</p>
<p><span class="math display">\[Var(\hat{\beta_{0}})=\sigma^{2}C_{00}=\]</span> <span class="math display">\[Var(\hat{\beta_{1}})=\sigma^{2}C_{11}=\]</span> <span class="math display">\[Var(\hat{\beta_{2}})=\sigma^{2}C_{22}=\]</span> <span class="math display">\[Cov(\hat{\beta_{0}},\hat{\beta_{1}})=\sigma^{2}C_{01}=\]</span> <span class="math display">\[Cov(\hat{\beta_{0}},\hat{\beta_{2}})=\sigma^{2}C_{02}=\]</span> <span class="math display">\[Cov(\hat{\beta_{1}},\hat{\beta_{2}})=\sigma^{2}C_{12}=\]</span> La estimación de <span class="math inline">\(\sigma^{2}\)</span> <span class="math display">\[
\boldsymbol{Y&#39;Y}=
\]</span> <span class="math display">\[
\boldsymbol{\hat{\beta}&#39;X&#39;Y}=
\]</span> <span class="math display">\[
\boldsymbol{\hat{\beta}&#39;X&#39;Y}=
\]</span> Por lo tanto, la suma de cuadrados del error es:</p>
<p><span class="math display">\[
SCE = \boldsymbol{Y&#39;Y - \hat{\beta}&#39;X&#39;Y}=
\]</span> Por consiguiente, la estimación de <span class="math inline">\(\sigma^{2}\)</span> es:</p>
<p><span class="math display">\[
\hat{\sigma}^{2}=CME=\frac{SCE}{n-p}=
\]</span></p>
</div>
<div id="prueba-de-hipótesis-en-la-regresión-múltiple" class="section level2 hasAnchor" number="1.8">
<h2><span class="header-section-number">1.8</span> Prueba de hipótesis en la regresión múltiple<a href="ejemplo-1.html#prueba-de-hipótesis-en-la-regresión-múltiple" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En problemas de regresión lineal múltiple, existen ciertas pruebas de hipótesis sobre los parámetros del modelo que son útiles para medir la adecuación del mismo. Al igual que en el caso de la regresión lineal simple, la prueba de hipótesis requiere que los términos error <span class="math inline">\(e_{i}\)</span> del modelo de regresión tengan distribuciones normales e independientes con media cero y varianza constante <span class="math inline">\(\sigma^{2}\)</span>.</p>
<div id="prueba-para-la-significancia-de-la-regresión." class="section level3 hasAnchor" number="1.8.1">
<h3><span class="header-section-number">1.8.1</span> Prueba para la significancia de la regresión.<a href="ejemplo-1.html#prueba-para-la-significancia-de-la-regresión." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La prueba para la significancia de la regresión es una prueba para determinar si existe una relación lineal entre las variables respuesta y y un conjunto de las variables independientes <span class="math inline">\(x_{1},x_{2},...,x_{k}\)</span>. Las hipótesis apropiados son:</p>
<p><span class="math display" id="eq:hipotesis-nula">\[
\begin{equation}
H_{0}:\beta_{1}=\beta_{2}=...=\beta_{k}=0
\end{equation}
\tag{1.14}
\]</span> <span class="math display" id="eq:hipotesis-alternativa">\[
\begin{equation}
H_{1}:\beta_{1}≠0
\tag{1.15}
\end{equation}
\]</span> Al menos para una j, siendo j = 1,2,…,k.</p>
<p>El rechazo de <span class="math inline">\(H_{0}:\beta_{1}=\beta_{2}=...=\beta_{k}=0\)</span> implica que al menos una de las variables de regresión <span class="math inline">\(x_{1},x_{2},...,x_{k}\)</span> tiene una contribución significativa en el modelo.</p>
<p>La prueba de significancia de la regresión es una generalización del procedimiento utilizando en la regresión lineal simple. La suma de cuadrado total SCT se divide en una suma de cuadrados debida a la regresión y una suma de cuadrados debida al error,</p>
<p><span class="math display" id="eq:identidad-total">\[
\begin{equation}
SCT=SCR+SCE
\tag{1.16}
\end{equation}
\]</span> <span class="math inline">\(SCR/\sigma^{2} \sim X_{K}^2\)</span> con k grados de libertad igual al número de variables regresoras y <span class="math inline">\(SCR/\sigma^{2} \sim X_{n-K-1}^2\)</span> 1 k n − − χ con n – k – 1 grados de libertad. Por lo tanto el estadístico de prueba viene dada por:</p>
<p><span class="math display" id="eq:estadistico-F">\[
\begin{equation}
F_{0}= \frac{SCR/k}{SCE/n-k-1}=\frac{CMR}{CME}
\tag{1.17}
\end{equation}
\]</span> Decisión: Se rechaza <span class="math inline">\(H_{0}\)</span> si <span class="math inline">\(F_{0}&gt;f_{\alpha;k,n-k-1}\)</span></p>
<p>En general, el procedimiento se resume en una tabla de análisis de varianza, tal como se muestra en la siguiente tabla:</p>
<p>Siendo: <span class="math display" id="eq:sce-formula">\[
\begin{equation}
SCE = \boldsymbol{Y&#39;Y - \hat{\beta}&#39;X&#39;Y}
\tag{1.18}
\end{equation}
\]</span> <span class="math display">\[
\begin{equation}
SCT=S_{yy}= \boldsymbol{Y&#39;Y}-\frac{\bigg(\sum_{i=1}^{2}Y_{i}\bigg)^{2}}{n} = \sum_{i=1}^{2}Y_{i}^{2}- \frac{\bigg(\sum_{i=1}^{2}Y_{i}\bigg)^{2}}{n}
\end{equation}
\]</span></p>
<p>Entonces, <span class="math display">\[
\begin{equation}
SCR=S_{yy}-SCE
(\#eq:scr-formula)
\end{equation}
\]</span> <span class="math display">\[
SCR= \boldsymbol{Y&#39;Y}-\frac{\bigg(\sum_{i=1}^{2}Y_{i}\bigg)^{2}}{n}-[\boldsymbol{Y&#39;Y-\hat{\beta}&#39;X&#39;Y}]
\]</span> Por consiguiente, la suma de cuadrados debida a la regresión, es:</p>
<p><span class="math display">\[
SCR= \boldsymbol{\hat{\beta}X&#39;Y}-\frac{\bigg(\sum_{i=1}^{2}Y_{i}\bigg)^{2}}{n}
\]</span></p>
</div>
<div id="prueba-para-los-coeficientes-de-regresión." class="section level3 hasAnchor" number="1.8.2">
<h3><span class="header-section-number">1.8.2</span> Prueba para los coeficientes de regresión.<a href="ejemplo-1.html#prueba-para-los-coeficientes-de-regresión." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A menudo se tiene interés en hacer pruebas de hipótesis sobre los coeficientes de regresión. Tales pruebas son útiles para determinar el valor potencial de cada una de las variables de regresión del modelo de regresión. Por ejemplo, el modelo puede ser más eficaz con la inclusión de variables adicionales, o quizás con la eliminación de uno o más de las regresoras presentes en el modelo.</p>
<p>Las hipótesis para la prueba de la significancia de cualquier coeficiente de regresión individual, por ejemplo, <span class="math inline">\(\beta_{j}\)</span>, son: <span class="math display">\[
\begin{equation}
H_{0}:\beta_{j}=0
(\#eq:hipotesis-nula-coeficiente)
\end{equation}
\]</span></p>
<p><span class="math display" id="eq:hipotesis-alternativa-coeficiente">\[
\begin{equation}
H_{0}:\beta_{j}≠0
\tag{1.19}
\end{equation}
\]</span> Si no se rechaza <span class="math inline">\(H_{0}:\beta_{j}=0\)</span>,entonces esto indica que la variable regresora <span class="math inline">\(x_{j}\)</span> puede eliminarse del modelo. El estadístico de prueba para esta hipótesis es:</p>
<p><span class="math display" id="eq:estadistico-t">\[
\begin{equation}
t_{0}=\frac{\hat{\beta_{j}}}{\sqrt{\hat{\sigma}^{2}C_{jj}}}
\tag{1.20}
\end{equation}
\]</span> donde <span class="math inline">\(C_{jj}\)</span> es el elemento de la diagonal principal de <span class="math inline">\(\boldsymbol{(X&#39;X)^{-1}}\)</span> que corresponde a <span class="math inline">\(\hat{\beta_{j}}\)</span></p>
<p>Decisión: Se rechaza <span class="math inline">\(H_{0}\)</span> si <span class="math inline">\(|t_{0}|&gt;t_{1-\alpha/2;n-p}\)</span></p>
<p>La siguiente tabla muestra los coeficientes de regresión con sus respectivos valores de t.</p>
<p>También puede emplearse el valor P para obtener conclusiones. Puesto que los valores de P menores que <span class="math inline">\(\alpha=5\)</span>%, conducen al rechazo las hipótesis nulas, lo que indica que las dos variables regresoras tienen contribución en el modelo.</p>
<p>Nótese que esta prueba mide la contribución parcial de <span class="math inline">\(x_{2}\)</span>, dado que <span class="math inline">\(x_{1}\)</span> aparece en el modelo esto es, la prueba t mide la contribución que tiene la adición de la variable</p>
<p>Existe otra manera de probar la contribución al modelo de cada variable de regresión. Este enfoque determina el aumento de la suma de los cuadrados de la regresión obtenida al agregar una variable <span class="math inline">\(x_{j}\)</span> al modelo, dado que las demás variables x_{i} (i ≠ j) ya están incluidas en la ecuación de regresión.</p>
</div>
</div>
<div id="estimación-de-los-intervalos-de-confianza-en-la-regresión-lineal-múltiple" class="section level2 hasAnchor" number="1.9">
<h2><span class="header-section-number">1.9</span> Estimación de los intervalos de confianza en la regresión lineal múltiple<a href="ejemplo-1.html#estimación-de-los-intervalos-de-confianza-en-la-regresión-lineal-múltiple" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="intervalos-de-confianza-para-los-parámetros." class="section level3 hasAnchor" number="1.9.1">
<h3><span class="header-section-number">1.9.1</span> Intervalos de confianza para los parámetros.<a href="ejemplo-1.html#intervalos-de-confianza-para-los-parámetros." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En los modelos de regresión múltiple, a menudo es útil construir estimaciones de intervalos de confianza para los coeficientes de regresión <span class="math inline">\(\beta_{j}\)</span>. El desarrollo de un procedimiento para obtener estos intervalos de confianza requiere que los errores <span class="math inline">\(\varepsilon_{i}\)</span>, estén distribuidos de manera normal e independientemente, con media cero y varianza constante <span class="math inline">\(\sigma_{2}\)</span>. Ésta es la misma suposición que se requiere para la prueba de hipótesis. Por consiguiente, las observaciones <span class="math inline">\(y_{i}\)</span> están normal e independientemente distribuidas con media y varianza. Puesto que el estimador de M.C.O. <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> es una combinación lineal de las observaciones, se desprende entonces que <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> tiene una distribución normal con un vector promedio <span class="math inline">\(\beta_{0}+\sum_{j=1}^{n}\beta_{j}x_{ij}\)</span> y matriz de varianza-covarianza <span class="math inline">\(\sigma^{2}\boldsymbol{(X&#39;X)^{-1}}\)</span>. Entonces, cada uno de los estadísticos</p>
<p><span class="math display">\[
\frac{\hat{\beta_{j}}}{\sqrt{\hat{\sigma}^{2}C_{jj}}}
\hspace{3.0cm}j = 0,1,...,k
\]</span> tienen distribución t con n – p grados de libertad, donde <span class="math inline">\(C_{jj}\)</span> es el j-ésimo elemento de la matriz <span class="math inline">\(\boldsymbol{(X&#39;X)^{-1}}\)</span> y <span class="math inline">\(\hat{\sigma}^{2}\)</span> es la estimación de la varianza del error.</p>
<p>Un intervalo de confianza del <span class="math inline">\((1-\alpha)100\)</span>% para el coeficiente de regresión <span class="math inline">\(\beta_{j}\)</span>, j = 0,1,…,k está dado por:</p>
<p><span class="math display">\[
\begin{equation}
\hat{\beta}-t_{\alpha/2;n-p}\sqrt{\hat{\sigma}^{2}C_{jj}}\leq \beta_{j}\leq\hat{\beta}+t_{\alpha/2;n-p}\sqrt{\hat{\sigma}^{2}C_{jj}}
\end{equation}
\]</span></p>
</div>
<div id="intervalo-de-confianza-para-la-respuesta-media-eyx0." class="section level3 hasAnchor" number="1.9.2">
<h3><span class="header-section-number">1.9.2</span> Intervalo de confianza para la respuesta media e(y/x0).<a href="ejemplo-1.html#intervalo-de-confianza-para-la-respuesta-media-eyx0." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>También puede obtenerse un intervalo de confianza para la respuesta promedio en un punto en particular, por ejemplo, <span class="math inline">\(x_{01},x_{02},...,x_{0k}\)</span>. Para estimar la respuesta promedio en este punto, se define el vector:</p>
<p><span class="math display">\[
\boldsymbol{x_{0}}=\begin{bmatrix}
1\\
x_{01}\\
x_{02}\\
\vdots \\
x_{0k}
\end{bmatrix}
\]</span> El valor estimado para este punto es: <span class="math inline">\(\hat{\mu}_{y/x_{0}}=\boldsymbol{x&#39;_{0}\hat{\beta}}\)</span>.</p>
<p>Este es un estimador insesgado de <span class="math inline">\(\mu_{y/x_{0}}\)</span>, siendo <span class="math inline">\(E(\hat{\mu}_{y/x_{0}})=\boldsymbol{x&#39;_{0}\hat{\beta}}=\mu_{y/x_{0}}\)</span> y la varianza <span class="math inline">\(V(\hat{\mu}_{y/x_{0}})=\sigma^{2}\boldsymbol{x&#39;_{0}(X&#39;X)^{-1}x_{0}}.\)</span></p>
<p>Entonces, un intervalo de confianza del <span class="math inline">\((1-\alpha)100\)</span>% para la respuesta media en el punto <span class="math inline">\(x_{01},x_{02},...,x_{0k};\)</span> está dado por:</p>
<p><span class="math display">\[
\begin{equation}
\hat{\mu}_{y/x_{0}}-t_{\alpha/2;n-p}\sqrt{\sigma^{2}\boldsymbol{x&#39;_{0}(X&#39;X)^{-1}x_{0}}}\leq\mu_{y/x_{0}}\leq\hat{\mu}_{y/x_{0}}+t_{\alpha/2;n-p}\sqrt{\sigma^{2}\boldsymbol{x&#39;_{0}(X&#39;X)^{-1}x_{0}}}
\end{equation}
\]</span></p>
<p>Ejemplo:</p>
<p>La respuesta promedio estimada en este punto es:</p>
<p>La varianza de <span class="math inline">\(V(\hat{\mu}_{y/x_{0}})\)</span> se estima por:</p>
<p><span class="math display">\[
\sigma^{2}\boldsymbol{x&#39;_{0}(X&#39;X)^{-1}x_{0}}=
\]</span> Entonces, el intervalo de confianza para la respuesta promedio es:</p>
</div>
<div id="intervalo-de-confianza-para-haty_0-observación-futura." class="section level3 hasAnchor" number="1.9.3">
<h3><span class="header-section-number">1.9.3</span> Intervalo de confianza para <span class="math inline">\(\hat{y}_{0}\)</span> (observación futura).<a href="ejemplo-1.html#intervalo-de-confianza-para-haty_0-observación-futura." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El modelo de regresión puede ser usado para predecir las observaciones futuras para un y correspondiente a un valor particular de las variables independientes, por ejemplo, <span class="math inline">\(x_{01},x_{02},...,x_{0k}.\)</span></p>
<p><span class="math display">\[
\boldsymbol{x_{0}}=\begin{bmatrix}
1&amp;  x_{01}&amp;  x_{02}&amp;  \cdots&amp; x_{0k}
\end{bmatrix}
\]</span> entonces una estimación de la observación futura y0 en el punto <span class="math inline">\(x_{01},x_{02},...,x_{0k}\)</span> es: <span class="math inline">\(\hat{y}_{0}=\boldsymbol{x&#39;_{0}\hat{\beta}}.\)</span></p>
<p>Un intervalo de confianza del <span class="math inline">\((1-\alpha)\)</span>% para una observación futura <span class="math inline">\(y_{0}\)</span> en el valor <span class="math inline">\(x_{0}\)</span>, está dado por:</p>
<p><span class="math display">\[
\begin{equation}
\hat{y_{0}}-t_{\alpha/2;n-p}\sqrt{\sigma^{2}\boldsymbol{x&#39;_{0}(X&#39;X)^{-1}x_{0}}}\leq y_{0}\leq\hat{y_{0}}+t_{\alpha/2;n-p}\sqrt{\sigma^{2}\boldsymbol{x&#39;_{0}(X&#39;X)^{-1}x_{0}}}
\end{equation}
\]</span></p>







<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
Webster, Allen L. 2000. <em>Estad<span>ı́</span>stica Aplicada a Los Negocios y La Econom<span>ı́</span>a</em>. 519.5 W391e Ej. 1. McGraw-Hill,.
</div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modelos-de-regresión-lineal-múltiple.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/01-intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
